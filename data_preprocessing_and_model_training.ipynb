{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14387953,"sourceType":"datasetVersion","datasetId":9188700},{"sourceId":14390142,"sourceType":"datasetVersion","datasetId":9190250}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- 1. IMPORTS & SETUP ---\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport xgboost as xgb\nimport optuna\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom torchvision import models, transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import r2_score\n\n# Configuration\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using Device: {DEVICE}\")\n\n# Locate Image Directory\nIMG_DIR = None\nfor root, dirs, files in os.walk('/kaggle/input'):\n    if sum(1 for f in files if f.endswith('.jpg')) > 100:\n        IMG_DIR = root\n        break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 2. DATA LOADING & GEOSPATIAL EDA ---\nprint(\"Loading Data...\")\ndf_train = pd.read_excel('/kaggle/input/cdcpro/train(1).xlsx')\ndf_test = pd.read_excel('/kaggle/input/cdcpro/test2.xlsx')\nfull_df = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n\n# 2.1 Geospatial Plot\n# We plot Latitude vs Longitude, colored by Price (Log scale for visibility)\nplt.figure(figsize=(10, 8))\nplt.title(\"Geospatial Analysis: House Prices by Location\")\nsns.scatterplot(\n    x=df_train['long'], \n    y=df_train['lat'], \n    hue=np.log1p(df_train['price']), \n    palette='coolwarm', \n    alpha=0.6,\n    s=10\n)\nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.legend(title=\"Log(Price)\")\nplt.show()\n\nprint(\"Observation: High prices (Red) are clustered around water bodies and specific northern neighborhoods.\")\n\n# --- NEW ADDITIONS BELOW ---\n\n# 2.2 Price Distribution (Checking for Skewness)\nplt.figure(figsize=(10, 5))\nsns.histplot(np.log1p(df_train['price']), kde=True, bins=50, color='purple')\nplt.title(\"Distribution of Target Variable: Log(Price)\")\nplt.xlabel(\"Log(Price)\")\nplt.show()\nprint(\"Observation: Log-transforming the price fixes the heavy right-skew, making it Gaussian-like.\")\n\n# 2.3 Feature Correlation Heatmap\nplt.figure(figsize=(12, 10))\n# Select only numeric columns to avoid errors\nnumeric_df = df_train.select_dtypes(include=[np.number])\n# Calculate correlation matrix\ncorr_matrix = numeric_df.corr()\n# Filter to show only features that correlate strongly with Price (> 0.3 or < -0.3)\ntop_features = corr_matrix.index[abs(corr_matrix[\"price\"]) > 0.3]\nsns.heatmap(df_train[top_features].corr(), annot=True, cmap='RdYlGn', fmt=\".2f\", linewidths=0.5)\nplt.title(\"Correlation Heatmap (Top Drivers of Price)\")\nplt.show()\n\n# 2.4 House Grade vs. Price (Box Plot)\nplt.figure(figsize=(12, 6))\nsns.boxplot(x=df_train['grade'], y=np.log1p(df_train['price']), palette='viridis')\nplt.title(\"Impact of Construction Grade on Price\")\nplt.xlabel(\"Grade (1-13)\")\nplt.ylabel(\"Log(Price)\")\nplt.show()\nprint(\"Observation: There is a clear exponential relationship between construction Grade and Price.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 3. TABULAR FEATURE ENGINEERING ---\nfull_df['date'] = pd.to_datetime(full_df['date'])\nfull_df['sale_year'] = full_df['date'].dt.year\nfull_df['sale_month'] = full_df['date'].dt.month\nfull_df['house_age'] = full_df['sale_year'] - full_df['yr_built']\n\n# Create bins for \"Micro-Neighborhoods\"\nfull_df['lat_bin'] = (full_df['lat'] // 0.02).astype(int)\nfull_df['long_bin'] = (full_df['long'] // 0.02).astype(int)\n\n# Feature: Neighborhood Density (Average size of nearby houses)\nfull_df['neighborhood_density'] = full_df.groupby(['lat_bin', 'long_bin'])['sqft_living'].transform('mean')\n\n# Feature: Neighborhood Price Grade\nfull_df['neighborhood_price_grade'] = full_df.groupby(['zipcode'])['grade'].transform('mean')\n\nfull_df['id'] = full_df['id'].astype(str)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 4. MODEL EXPLAINABILITY (GRAD-CAM) ---\n# Helper function to process image\ndef get_image_tensor(img_path):\n    img = Image.open(img_path).convert('RGB')\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    return transform(img).unsqueeze(0).to(DEVICE), img\n\n# Hook-based Grad-CAM\nclass GradCAM:\n    def __init__(self, model, target_layer):\n        self.model = model\n        self.gradients = None\n        self.activations = None\n        \n        # Hooks\n        target_layer.register_forward_hook(self.save_activation)\n        target_layer.register_backward_hook(self.save_gradient)\n\n    def save_activation(self, module, input, output):\n        self.activations = output\n\n    def save_gradient(self, module, grad_input, grad_output):\n        self.gradients = grad_output[0]\n\n    def __call__(self, x):\n        self.model.zero_grad()\n        output = self.model(x)\n        \n        target = output[:, 0] \n        target.backward()\n        \n        gradients = self.gradients.cpu().data.numpy()[0]\n        activations = self.activations.cpu().data.numpy()[0]\n        \n        weights = np.mean(gradients, axis=(1, 2))\n        cam = np.zeros(activations.shape[1:], dtype=np.float32)\n        \n        for i, w in enumerate(weights):\n            cam += w * activations[i]\n            \n        cam = np.maximum(cam, 0)\n        cam = cv2.resize(cam, (224, 224))\n        cam = cam - np.min(cam)\n        cam = cam / np.max(cam)\n        return cam\n\n# Load Model for Visualization\nprint(\"Initializing Grad-CAM Model...\")\ncam_model = models.efficientnet_b0(pretrained=True).to(DEVICE)\ncam_model.eval()\n\n# Target the last convolutional layer in EfficientNet\ntarget_layer = cam_model.features[-1] \ngrad_cam = GradCAM(cam_model, target_layer)\n\nfound_image = False\nimg_path = \"\"\n\nif IMG_DIR and os.path.exists(IMG_DIR):\n    # List files and pick the first JPG found\n    files = [f for f in os.listdir(IMG_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n    if len(files) > 0:\n        img_path = os.path.join(IMG_DIR, files[0]) # Pick the first available image\n        found_image = True\n        print(f\"Found sample image for explanation: {files[0]}\")\n    else:\n        print(f\"Error: No images found in directory {IMG_DIR}\")\nelse:\n    print(\"Error: IMG_DIR not found.\")\n\nif found_image:\n    input_tensor, original_img = get_image_tensor(img_path)\n    heatmap = grad_cam(input_tensor)\n    \n    # Overlay heatmap on image\n    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n    \n    # Resize original image to match heatmap (224x224)\n    original_img = original_img.resize((224, 224))\n    superimposed = np.uint8(0.6 * np.array(original_img) + 0.4 * heatmap)\n\n    # Plot\n    plt.figure(figsize=(12, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.title(\"Original House Image\")\n    plt.imshow(original_img)\n    plt.axis('off')\n    \n    plt.subplot(1, 2, 2)\n    plt.title(\"AI Attention Map (Red = High Importance)\")\n    plt.imshow(superimposed)\n    plt.axis('off')\n    \n    plt.show()\n    print(\"Explanation: The Red/Yellow areas show which parts of the image (e.g., greeneries/roof) the CNN focused on to generate the embedding.\")\nelse:\n    print(\"Skipping Grad-CAM visualization due to missing images.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 5. VISUAL FEATURE EXTRACTION ---\n\n# Define Dataset\nclass FeatureExtractionDataset(Dataset):\n    def __init__(self, dataframe, image_dir):\n        self.df = dataframe.reset_index(drop=True)\n        self.image_dir = image_dir\n        self.transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.image_dir, f\"{str(row['id'])}.jpg\")\n        try:\n            image = Image.open(img_path).convert('RGB')\n            image = self.transform(image)\n        except:\n            image = torch.zeros((3, 224, 224)) \n        return image, row['id']\n\n# Load Model (Identity Head)\nmodel = models.efficientnet_b0(pretrained=True).to(DEVICE)\nmodel.classifier = nn.Identity()\nmodel.eval()\n\ndataset = FeatureExtractionDataset(full_df[['id']], IMG_DIR)\nloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=2)\n\nprint(\"Extracting Visual Features...\")\nfeatures_list = []\nids_list = []\n\nwith torch.no_grad():\n    for imgs, batch_ids in tqdm(loader):\n        imgs = imgs.to(DEVICE)\n        embeddings = model(imgs)\n        features_list.append(embeddings.cpu().numpy())\n        ids_list.extend(batch_ids)\n\nall_features = np.vstack(features_list)\nfeat_cols = [f'img_{i}' for i in range(all_features.shape[1])]\nimg_df = pd.DataFrame(all_features, columns=feat_cols)\nimg_df['id'] = ids_list","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 6. FUSION ARCHITECTURE & PCA ---\n\n# Merge Tabular + Visual\nprint(\"Performing Late Fusion (Merging Data)...\")\nimg_df['id'] = img_df['id'].astype(str)\nimg_df = img_df.drop_duplicates(subset=['id'])\nmerged_df = pd.merge(full_df, img_df, on='id', how='left')\n\n# PCA Compression\nprint(\"Reducing Dimensions (1280 -> 50)...\")\nimg_cols = [c for c in img_df.columns if c.startswith('img_')]\npca = PCA(n_components=50, random_state=42)\npca_features = pca.fit_transform(merged_df[img_cols].fillna(0))\n\npca_cols = [f'pca_img_{i}' for i in range(50)]\npca_df = pd.DataFrame(pca_features, columns=pca_cols)\n\nmerged_df = merged_df.drop(columns=img_cols)\nmerged_df = pd.concat([merged_df, pca_df], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 7. OPTUNA TUNING ---\n\n# 7.1 Define Features\ntab_features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n                'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n                'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n                'lat', 'long', 'sqft_living15', 'sqft_lot15',\n                'house_age', 'sale_month', 'lat_bin', 'long_bin', \n                'neighborhood_density', 'neighborhood_price_grade']\nall_features = tab_features + pca_cols\n\n# 7.2 Split Data\ntrain_data = merged_df[merged_df['price'].notna()]\ntest_data = merged_df[merged_df['price'].isna()]\n\nX = train_data[all_features]\ny = np.log1p(train_data['price']) \n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n\ndef objective(trial):\n    params = {\n        'objective': 'reg:squarederror',\n        'tree_method': 'hist',      \n        'device': 'cuda',           \n        'n_estimators': trial.suggest_int('n_estimators', 2000, 6000),\n        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05),\n        'max_depth': trial.suggest_int('max_depth', 4, 10),\n        'subsample': trial.suggest_float('subsample', 0.5, 0.9),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 0.8),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n        'n_jobs': -1,\n        'random_state': 42,\n        'early_stopping_rounds': 100\n    }\n    \n    model = xgb.XGBRegressor(**params)\n    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n    \n    preds = model.predict(X_val)\n    return r2_score(y_val, preds)\n\n# 7.4 Run Study\nprint(\"Starting Optuna Optimization...\")\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=30) \n\nprint(\"Best Params Found:\", study.best_params)\nbest_params = study.best_params","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 7. HYPERPARAMETER TUNING & TRAINING ---\n\ntab_features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n                'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n                'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n                'lat', 'long', 'sqft_living15', 'sqft_lot15',\n                'house_age', 'sale_month', 'lat_bin', 'long_bin', \n                'neighborhood_density', 'neighborhood_price_grade']\nall_features = tab_features + pca_cols\n\ntrain_data = merged_df[merged_df['price'].notna()]\ntest_data = merged_df[merged_df['price'].isna()]\n\nX = train_data[all_features]\ny = np.log1p(train_data['price'])\nX_test = test_data[all_features]\n\n\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\noof_preds = np.zeros(len(X))\ntest_preds_sum = np.zeros(len(X_test))\n\nprint(\"Starting 5-Fold Cross-Validation...\")\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n    \n    model = xgb.XGBRegressor(**best_params)\n    model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], verbose=False)\n    \n    val_pred = model.predict(X_val_fold)\n    oof_preds[val_idx] = val_pred\n    test_preds_sum += model.predict(X_test)\n    \n    print(f\"Fold {fold+1} R2: {r2_score(y_val_fold, val_pred):.5f}\")\n\nprint(f\"\\nOverall CV Score: {r2_score(y, oof_preds):.5f}\")\n\nfinal_preds_log = test_preds_sum / 5\nfinal_preds_real = np.expm1(final_preds_log)\nsubmission = pd.DataFrame({\n    'id': test_data['id'], \n    'price': final_preds_real\n})\nsubmission.to_csv('submission_final.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}